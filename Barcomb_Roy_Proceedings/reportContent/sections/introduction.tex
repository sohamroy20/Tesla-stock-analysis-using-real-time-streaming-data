\section*{Introduction}

In recent years, the volume of data generated by financial markets has grown exponentially, increasing the importance of efficient and scalable data analysis solutions. This project leverages Apache Spark, a widely used open-source framework designed for big data processing, to perform real-time data analysis on simulated streaming data from Tesla's stock market history.
\newline

The objective of this project was to design, implement, and deploy a robust data streaming analysis pipeline capable of handling continuous input data. To simulate the streaming environment, a historical dataset containing Tesla's stock prices was used, with data being progressively introduced to mimic live market feeds. Initial development and testing was carried out locally using Python to ensure the correctness and functionality of the Spark application prior to deployment.
\newline

As such, to demonstrate scalability and real-world applicability, the Spark application was deployed on a distributed computing environment consisting of a three-node AWS EC2 cluster. This setup utilized Hadoop Distributed File System (HDFS) for data storage and Apache YARN as the resource management system, allowing the Spark application to efficiently distribute tasks and manage computational resources.
\newline

This report covers the methodology, implementation steps, and insights gained from processing the simulated real-time streaming data. With it, we hope to highlight the strengths of Apache Spark in handling high-throughput analysis tasks and showcase the potential scalability of our project.
\newline