\section*{Conclusion}

This project successfully demonstrated the feasibility and effectiveness of using Apache Spark for real-time anomaly detection in streaming financial data. Using historical Tesla stock data to simulate a real-time streaming environment, the ability of distributed systems to provide insights into stock market behavior was effectively demonstrated.
\newline

The implementation utilized advanced statistical techniques such as EWMA, z-score, and Bollinger bands, which proved effective in detecting anomalies and providing indicators for potential market actions. The deployment on AWS using a Hadoop and YARN-based three-node EC2 cluster validated the project's scalability and relevance to real-world big data processing scenarios.
\newline

Throughout this project, several insights were gained regarding the configuration and optimization of distributed streaming applications, especially in terms of deployment strategies, data pipeline design, and visualization techniques. Additionally, the modular design facilitated ease of debugging and maintenance, which was critical once the transition to cloud deployment began, requiring us to make fast, iterative changes to our streaming application and visual dashboard script.
\newline

Future work could explore further scaling the architecture to handle much larger datasets and faster streaming rates, improving dashboard interactivity for more advanced analytics, and improving anomaly detection accuracy with machine learning approaches. Overall, this project contributed valuable practical experience to us and provided a strong foundation for further research and application in distributed systems and financial data analytics.
\newline